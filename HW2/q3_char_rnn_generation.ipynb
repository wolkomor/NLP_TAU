{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python (nlp-hw2-q3)",
      "language": "python",
      "name": "nlp-hw2-q3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    },
    "colab": {
      "name": "q3_char-rnn-generation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wolkomor/NLP_TAU/blob/master/HW2/q3_char_rnn_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ioAe5jRyxKL",
        "colab_type": "text"
      },
      "source": [
        "### Submission Instructions:\n",
        "1. **Restart the kernel** (in the menubar, select Runtime$\\rightarrow$Restart runtime)\n",
        "2. **Run all cells** (in the menubar, select Runtime$\\rightarrow$Run All).\n",
        "3. **Download the notebook** (in the menubar, select File$\\rightarrow$Download .ipynb)\n",
        "4. **Add the downloaded notebook (.ipynb file) to the submission zip**.\n",
        "\n",
        "Make sure you fill in any place that says `YOUR CODE HERE` or \"**WRITE YOUR ANSWER IN THIS CELL**\", and that no tests fail.  \n",
        "Write the IDs of all group members in the cell below. Leave any surplus IDs as `\"\"`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpzjm6glyxKN",
        "colab_type": "text"
      },
      "source": [
        "ID1 = 308402163\n",
        "ID2 = 204351019  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1IG_nhFyxKO",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "5493400e8b7f9a8e2cde874866d4fa7f",
          "grade": false,
          "grade_id": "cell-3a1bca1dbb7d0069",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "0YQnIO6dyxKO",
        "colab_type": "text"
      },
      "source": [
        "![shakespeare](https://i.imgur.com/81YZuel.jpg)\n",
        "\n",
        "# Generating Shakespeare Using a Character-level Language Model\n",
        "\n",
        "### From Words to Characters\n",
        "In the previous two sections we dealt with word-level language models. But looking again at section 2, there is nothing that constraints us to using _words_ as the basic elemnents in our model. The model we analyzed in section 2 could just as well be character-based - just replace \"word\" with \"character\", and you are good to go. In this notebook we will train a small character-based language model that will help us generate Shakespearean-like (emphasis on the _like_...) texts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "9af7a343d0e3524c3fd846d987d766a8",
          "grade": false,
          "grade_id": "cell-7301754e4d655d01",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "qDb6LzkzyxKP",
        "colab_type": "text"
      },
      "source": [
        "### Question 3.a\n",
        "Can you think of an advantage a character-based language model could have over a word-based language model? _(You might find question 2.c useful)_. And what about the other way around: can you think of an advantage a word-based language model could have over a character-based language model?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "eb742db028fffc9c69d14202fc1e24bd",
          "grade": true,
          "grade_id": "cell-e19646c939692ee9",
          "locked": false,
          "points": 4,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "vL-FK3-RyxKQ",
        "colab_type": "text"
      },
      "source": [
        "**WRITE YOUR ANSWER IN THIS CELL**\n",
        "\n",
        "Word-based model - not Gibberish words in generated text. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "d46a8dfd340b8f68e51a041307f7d7d3",
          "grade": false,
          "grade_id": "cell-ebc0d8ae3061c0fc",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "3YL64nZmyxKQ",
        "colab_type": "text"
      },
      "source": [
        "### Using PyTorch\n",
        "\n",
        "We'll build our language model using PyTorch. PyTorch is a [very popular](https://thegradient.pub/state-of-ml-frameworks-2019-pytorch-dominates-research-tensorflow-dominates-industry/) open-source machine learning (and deep learning) framework developed by Facebook. In short:\n",
        "\n",
        "> Pytorch is a Python-based scientific computing package targeted at two sets of audiences:\n",
        "* A replacement for NumPy to use the power of GPUs\n",
        "* A deep learning research platform that provides maximum flexibility and speed\n",
        "\n",
        "To get familiar with PyTorch, check out this [quick tutorial](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html). In addition, another imporant difference from numpy is that PyTorch can automatically calculate the gradients needed for backpropagation, as explained [here](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "02af8a21a2e8fae58d84f915de5b016d",
          "grade": false,
          "grade_id": "cell-aa2773db1bef7014",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "iQVJt2VsyxKR",
        "colab_type": "text"
      },
      "source": [
        "### Preparing the Data\n",
        "\n",
        "Our dataset is a plain text file. For simplicity, we turn any potential unicode characters into plain ASCII by using the `unidecode` package."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eL56o_yzJ4j",
        "colab_type": "code",
        "outputId": "079dfb05-b435-4f92-a08a-fc577e923d9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "!pip install unidecode"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\r\u001b[K     |█▍                              | 10kB 17.7MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20kB 6.0MB/s eta 0:00:01\r\u001b[K     |████▏                           | 30kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 40kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 51kB 6.5MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 61kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 71kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████                     | 81kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 92kB 10.5MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 102kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 112kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 122kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 133kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 143kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 153kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 163kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 174kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 184kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 194kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 204kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 215kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 225kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 235kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 245kB 8.5MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZva7BDJz4Nk",
        "colab_type": "code",
        "outputId": "15544bee-d442-4507-9117-2e21addfb5d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSUY2aI-1Da4",
        "colab_type": "code",
        "outputId": "b7a8e835-d4e9-4ef5-9520-841cfc53ae52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd '/content/drive/My Drive/Colab Notebooks/'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ef0359e8c08b2057771c115150011e7e",
          "grade": false,
          "grade_id": "cell-cce75419c097f3fd",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "is_executing": false
        },
        "id": "zJck8ViDyxKT",
        "colab_type": "code",
        "outputId": "70783abf-55d4-4d79-a57e-5116111301a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import string\n",
        "import random\n",
        "import re\n",
        "\n",
        "import unidecode\n",
        "\n",
        "all_characters = string.printable\n",
        "n_characters = len(all_characters)  # our vocabulary size (|V| from the handout)\n",
        "\n",
        "dataset_as_string = unidecode.unidecode(open('data/shakespeare.txt').read())\n",
        "n_chars_in_dataset = len(dataset_as_string)\n",
        "print(f'Total number of characters in our dataset: {n_chars_in_dataset}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of characters in our dataset: 1115394\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "06dd2ac91a6296206475c7e330e53e3d",
          "grade": false,
          "grade_id": "cell-d795f907dd7922f3",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "Rr3hy-GxyxKV",
        "colab_type": "text"
      },
      "source": [
        "To make inputs out of this big string of text, we will split it into chunks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "61947ad22fb7f16eba246d47ab8cae22",
          "grade": false,
          "grade_id": "cell-379f229536dae19b",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "is_executing": false
        },
        "id": "vjKfxl2VyxKV",
        "colab_type": "code",
        "outputId": "105861a8-9a3f-4892-81f0-41eab259fc04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "chunk_len = 400\n",
        "\n",
        "def random_chunk():\n",
        "    start_index = random.randint(0, n_chars_in_dataset - chunk_len)\n",
        "    end_index = start_index + chunk_len + 1\n",
        "    return dataset_as_string[start_index:end_index]\n",
        "\n",
        "print(random_chunk())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "having France thy friend, thou shalt not dread\n",
            "The scatter'd foe that hopes to rise again;\n",
            "For though they cannot greatly sting to hurt,\n",
            "Yet look to have them buzz to offend thine ears.\n",
            "First will I see the coronation;\n",
            "And then to Brittany I'll cross the sea,\n",
            "To effect this marriage, so it please my lord.\n",
            "\n",
            "EDWARD:\n",
            "Even as thou wilt, sweet Warwick, let it be;\n",
            "For in thy shoulder do I build my seat,\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "ba5d4900ff254fa335fe935962878c8d",
          "grade": false,
          "grade_id": "cell-fcbb2d73f4e442fb",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "9E0Zwvl5yxKX",
        "colab_type": "text"
      },
      "source": [
        "### Building Our Model\n",
        "\n",
        "Our model consists of three main components:\n",
        "\n",
        "1. [**Embedding**](https://pytorch.org/docs/stable/nn.html#embedding). A mapping between characters and their learned representations (\"word vectors\") \\[correspoding to ${\\boldsymbol L}$ in terms of the handout\\]\n",
        "2. [**GRU**](https://pytorch.org/docs/stable/nn.html#gru). \\[correspoding to the computation of ${\\boldsymbol h}^{(t)}$ in terms of the handout\\]\n",
        "3. **Output Layer**. A feed-forward neural network that transforms a hidden state at a timestep into a probability distribution of the next character. \\[correspoding to the computation of $\\hat{\\boldsymbol y}^{(t)}$ in terms of the handout\\] "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peQLqmOjyxKX",
        "colab_type": "text"
      },
      "source": [
        "### Question 3.b\n",
        "Complete the implementation of the `forward` method of our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a9ad1239fcd5aec23f439249397895ec",
          "grade": false,
          "grade_id": "cell-1640492438386e87",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "pycharm": {
          "is_executing": false
        },
        "id": "YbTECQvKyxKY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "\n",
        "class OurModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
        "        super(OurModel, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.num_layers = num_layers\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)  # In the terms of the handout, here d = D_h\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, num_layers)\n",
        "        self.output_layer = nn.Linear(hidden_size, output_size)\n",
        "    \n",
        "    def forward(self, input_, hidden):\n",
        "        # General instructions:\n",
        "        # Pass the embedded input through the GRU and use the output layer to get the next character distribution.\n",
        "        # return that distribution and the next hidden state.\n",
        "        # You may need to play around with the dimensions a bit until you get it right. Dimension-induced frustration is good for you!\n",
        "        # -------------------------\n",
        "        # YOUR CODE HERE\n",
        "        emb = self.embedding(input_)\n",
        "        output,hidden = self.gru(emb.view(-1, 1, self.hidden_size),hidden)\n",
        "        output = self.output_layer(output.view(-1, self.hidden_size))\n",
        "        # -------------------------\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return Variable(torch.zeros(self.num_layers, 1, self.hidden_size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "da793a49917dc4882e7e70f04d07a777",
          "grade": false,
          "grade_id": "cell-b9299fddeb082b4e",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "AZLem-9tyxKa",
        "colab_type": "text"
      },
      "source": [
        "### Creating the Training Examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "f6eaeb80c370b32f26eda2ac1be57444",
          "grade": false,
          "grade_id": "cell-83bf9e1b0374206c",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "mYIQ9oFOyxKa",
        "colab_type": "text"
      },
      "source": [
        "Each chunk will be turned into a tensor by looping through the characters of the string and looking up the index of each character in `all_characters`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "cc87bca342db2fde1b3957f48bcfe857",
          "grade": false,
          "grade_id": "cell-5360afdd0b03b1f4",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "is_executing": false
        },
        "id": "9DVgSRN8yxKb",
        "colab_type": "code",
        "outputId": "92fe333f-0210-4c5c-ca0e-91dbe54cc56a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Turn a string into list of longs\n",
        "def chars_to_tensor(string):\n",
        "    tensor = torch.zeros(len(string)).long()\n",
        "    for c in range(len(string)):\n",
        "        tensor[c] = all_characters.index(string[c])\n",
        "    return Variable(tensor)\n",
        "\n",
        "print(chars_to_tensor('abcDEF'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([10, 11, 12, 39, 40, 41])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "32c02aa64cee9046c2917487ac982de0",
          "grade": false,
          "grade_id": "cell-6e7b3d9e8c9396bb",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "oiIAl5PryxKc",
        "colab_type": "text"
      },
      "source": [
        "Each training example for our model will be created from a chunk randomly extracted from our shakespeare dataset. For example, if we set our chunk size to be 28, then a randomly extracted chunk could be $\\texttt{As deep as that, though true}$. Each training example is of a form $(\\textbf{x},\\textbf{y})$ where $\\textbf{x}$ is all the charecters of the chunk *except the last* and $\\textbf{y}$ is all the charecters of the chunk *except the first*. For example, given the chunk above, $\\textbf{x}=\\texttt{As deep as that, though tru}$ and $\\textbf{y}=\\texttt{s deep as that, though true}$. At timestep i our input is $\\textbf{x}^{(i)}$ and the gold label our model will try to predict is $\\textbf{y}^{(i)}$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f159d648c0ab9ffbdc096aeac6905a57",
          "grade": false,
          "grade_id": "cell-d3539c5f1d96a188",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "is_executing": false
        },
        "id": "dbKWx_vmyxKd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def random_training_example():    \n",
        "    chunk = random_chunk()\n",
        "    inp = chars_to_tensor(chunk[:-1])\n",
        "    target = chars_to_tensor(chunk[1:])\n",
        "    return inp, target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "18a6bf800d9bc590739b15ba01dda408",
          "grade": false,
          "grade_id": "cell-16d13f3b273395ac",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "WaPvJR72yxKe",
        "colab_type": "text"
      },
      "source": [
        "### Evaluating\n",
        "\n",
        "To evaluate the network we will feed one character at a time, use the outputs of the network as a probability distribution for the next character, and repeat. To start generation we pass a priming string to start building up the hidden state, from which we then generate one character at a time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a47c721a818979b886f119401206e756",
          "grade": false,
          "grade_id": "cell-44ab27a8fee696ad",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "is_executing": false
        },
        "id": "1m-kIn2zyxKf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def evaluate(prime_str='A', predict_len=100, temperature=0.8):\n",
        "    hidden = model.init_hidden()\n",
        "    prime_input = chars_to_tensor(prime_str)\n",
        "    predicted = prime_str\n",
        "\n",
        "    # Use priming string to \"build up\" hidden state\n",
        "    for p in range(len(prime_str) - 1):\n",
        "        _, hidden = model(prime_input[p], hidden)\n",
        "    inp = prime_input[-1]\n",
        "    \n",
        "    for p in range(predict_len):\n",
        "        output, hidden = model(inp, hidden)\n",
        "        \n",
        "        # Sample from the network as a multinomial distribution\n",
        "        output_dist =  F.softmax(output / temperature, dim=-1)\n",
        "        top_i = torch.multinomial(output_dist, 1)[0]\n",
        "        \n",
        "        # Add predicted character to string and use as next input\n",
        "        predicted_char = all_characters[top_i]\n",
        "        predicted += predicted_char\n",
        "        inp = chars_to_tensor(predicted_char)\n",
        "\n",
        "    return predicted"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "3fffa10554299eaae14cc007fea3935a",
          "grade": false,
          "grade_id": "cell-1d3fd015fe8f64d1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "7jI5dpEryxKh",
        "colab_type": "text"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "8a98218b35f47137eeba1ba1aead0700",
          "grade": false,
          "grade_id": "cell-a209b293a8850a57",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "VZlPcu70yxKi",
        "colab_type": "text"
      },
      "source": [
        "The main training function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "eb3bfcd4d49b2f2672447d8c65b6cb05",
          "grade": false,
          "grade_id": "cell-e246cbd9689e1a6d",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "is_executing": false
        },
        "id": "Ciz-iT-EyxKk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(inp, target):\n",
        "    hidden = model.init_hidden()\n",
        "    model.zero_grad()\n",
        "    loss = 0\n",
        "\n",
        "    for c in range(chunk_len):\n",
        "        output, hidden = model(inp[c], hidden)\n",
        "        loss += criterion(output, target[c].view(-1))\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item() / chunk_len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "bfb863e279db4b170c35d8d0c7a37a1f",
          "grade": false,
          "grade_id": "cell-05ce9b9275e0d1cc",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "oVCYnfPfyxKm",
        "colab_type": "text"
      },
      "source": [
        "A helper to print the amount of time passed:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "16d7b53f211a6a1bef71c1dd2d1271cf",
          "grade": false,
          "grade_id": "cell-cb78afef7022f9a1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "is_executing": false
        },
        "id": "ahSNOP6yyxKm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time, math\n",
        "\n",
        "def time_since(since):\n",
        "    s = time.time() - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return f'{m}m {math.floor(s)}s'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "2b368f1767ddd0eddca44249fa47ed32",
          "grade": true,
          "grade_id": "cell-98f46bec0b8c87cc",
          "locked": true,
          "points": 10,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "2hBq63iyyxKo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DO NOT DELETE THIS CELL\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "98abd7dd7805753c2e7b635f1265cb73",
          "grade": false,
          "grade_id": "cell-baf25642209867dc",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "gYAFxjLhyxKq",
        "colab_type": "text"
      },
      "source": [
        "Define the training parameters, instantiate the model, and start training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "b7392249521c153ef4d7713eecb8204a",
          "grade": false,
          "grade_id": "cell-4900f92ae503be69",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "is_executing": false
        },
        "id": "iCFtIGjbyxKq",
        "colab_type": "code",
        "outputId": "f06b7cbe-5fdb-41d3-8f0c-f4b67377f87d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "n_iterations = 2000\n",
        "print_every = 100\n",
        "plot_every = 10\n",
        "hidden_size = 100  # (D_h from the handout)\n",
        "num_layers = 1\n",
        "lr = 0.005\n",
        "\n",
        "model = OurModel(n_characters, hidden_size, n_characters, num_layers)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "start = time.time()\n",
        "all_losses = []\n",
        "loss_avg = 0\n",
        "\n",
        "for iteration in range(1, n_iterations + 1):\n",
        "    loss = train(*random_training_example())       \n",
        "    loss_avg += loss\n",
        "\n",
        "    if iteration % print_every == 0:\n",
        "        print(f'[time elapsed: {time_since(start)}  ;  iterations: {iteration} ({iteration / n_iterations * 100}%)  ;  loss: {loss:.4}]')\n",
        "        print(evaluate('Wh', 200), '\\n')  # generate text starting with 'Wh'\n",
        "\n",
        "    if iteration % plot_every == 0:\n",
        "        all_losses.append(loss_avg / plot_every)\n",
        "        loss_avg = 0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[time elapsed: 0m 36s  ;  iterations: 100 (5.0%)  ;  loss: 2.29]\n",
            "Wh bround day hare ther stures your, and the Lore hand maird amlo bet by, shen, hare lrors and an cous ning coot uris gely the bem.\n",
            "\n",
            "OUNM O:\n",
            "Non be and me, tos yor that to: bes;\n",
            "Whe bam my and cyou the  \n",
            "\n",
            "[time elapsed: 1m 12s  ;  iterations: 200 (10.0%)  ;  loss: 2.03]\n",
            "Whined it nove nood hesets ou to and filen soll patizem!\n",
            "Or comenof a spanes and thou wollous sond! grane Care of a then ofne mao, it in he lane noty, wereack ill on now porfs; it sonene hear, soo and s \n",
            "\n",
            "[time elapsed: 1m 48s  ;  iterations: 300 (15.0%)  ;  loss: 1.874]\n",
            "Whes my a thean hath mofest nastaindion the cold\n",
            "That, I vire,\n",
            "The know main congoith and not sir that ectas and the sher the in pray gondear I muss cay.\n",
            "For wher my here a has, masts of stoes the dor e \n",
            "\n",
            "[time elapsed: 2m 25s  ;  iterations: 400 (20.0%)  ;  loss: 1.781]\n",
            "Whers, my grove of thy here heap?\n",
            "\n",
            "DUNE Sthou sup,\n",
            "Ware we us to four it whicine hank he holine pratens'd ould reftemen with your his with is coulderee.\n",
            "\n",
            "COMEROUCESTER:\n",
            "For in his his frience him\n",
            "To pre \n",
            "\n",
            "[time elapsed: 3m 1s  ;  iterations: 500 (25.0%)  ;  loss: 1.75]\n",
            "Whave stease aperince: me of heading\n",
            "boloke a chace mean choth latiears.\n",
            "\n",
            "LOUCHENTIO:\n",
            "So cort. I with my the and stand.\n",
            "\n",
            "LABET:\n",
            "What the his shere but I do both it beet, I whorten to is kind Hast shave  \n",
            "\n",
            "[time elapsed: 3m 38s  ;  iterations: 600 (30.0%)  ;  loss: 1.913]\n",
            "Wher of the rames.\n",
            "\n",
            "Sovend prow RUCHENNE:\n",
            "Which he plittely the cack that thee contice:\n",
            "Was not ack as for are ins; mudst their chand thy caps a mead.\n",
            "\n",
            "PISEN:\n",
            "This queensous he apped make aly go\n",
            "gil her \n",
            "\n",
            "[time elapsed: 4m 14s  ;  iterations: 700 (35.0%)  ;  loss: 1.831]\n",
            "Wh speasefor suasander agin come princouds\n",
            "The a liven but to sope inging faurs,\n",
            "As my night to it wiffou ever:\n",
            "Adanters the but not the is thou shere's would this you noth poth\n",
            "Tothing think the his it \n",
            "\n",
            "[time elapsed: 4m 51s  ;  iterations: 800 (40.0%)  ;  loss: 1.801]\n",
            "Whire had hatoe known me frince,\n",
            "But fare propt und, lord?\n",
            "\n",
            "First: but bound off\n",
            "shete with the our prath they mave in using son to may have breetion: I burroung of\n",
            "Becas? I merarter my be mer'd, for ma \n",
            "\n",
            "[time elapsed: 5m 28s  ;  iterations: 900 (45.0%)  ;  loss: 1.848]\n",
            "Wh all congfenty staule's this him,\n",
            "Betle trure te spervench ever light my this be the is not us thente:\n",
            "And have thinks, fielf this artal\n",
            "Come the was this leve true dit of the I saytion wads\n",
            "Bit in th \n",
            "\n",
            "[time elapsed: 6m 4s  ;  iterations: 1000 (50.0%)  ;  loss: 1.939]\n",
            "Wher stand'd your.\n",
            "\n",
            "LINGET:\n",
            "You, my brople our so with with for may Marnide: saplunce this men\n",
            "The for you sir not, moring is please.\n",
            "\n",
            "Mike:\n",
            "They the you with your so consting,\n",
            "Hen, and solatior her it  \n",
            "\n",
            "[time elapsed: 6m 41s  ;  iterations: 1100 (55.00000000000001%)  ;  loss: 1.879]\n",
            "Whot the forthiry\n",
            "And: of flature cire seft well Porrord.\n",
            "\n",
            "CLORIZEL:\n",
            "Well your me, who evers nother,\n",
            "And me, lile able!\n",
            "Stweet cost he proverly to hage that fratee\n",
            "os fabullo congeat bettare.\n",
            "\n",
            "PRONIUS:\n",
            " \n",
            "\n",
            "[time elapsed: 7m 18s  ;  iterations: 1200 (60.0%)  ;  loss: 1.535]\n",
            "Whick befeak the can day.\n",
            "\n",
            "BIONDIUS:\n",
            "To have dear staw, hes true cleam, tell:\n",
            "I wistlest have with the fors a bettle ta farest.\n",
            "\n",
            "KING LENA:\n",
            "You say, for coult to exter.\n",
            "\n",
            "PERCICIA:\n",
            "Ao, go with undeist ve \n",
            "\n",
            "[time elapsed: 7m 54s  ;  iterations: 1300 (65.0%)  ;  loss: 1.577]\n",
            "Which agad come as as ton, and jead, them:\n",
            "\n",
            "BUCKINGHAM:\n",
            "Whor cromed the, I canger mest my cnown aldst\n",
            "The shall go which croir, you, back to may betting the do,\n",
            "Thou more then to long shor Edward:\n",
            "Thim. \n",
            "\n",
            "[time elapsed: 8m 31s  ;  iterations: 1400 (70.0%)  ;  loss: 1.921]\n",
            "Wher.\n",
            "\n",
            "ROLICHUS:\n",
            "He chame you was to they blow for to heir all is creace\n",
            "And help, hope heesin the's of entlest too newancelo's:\n",
            "In my heart; there the say not in me retich'd\n",
            "The blood blouce these live \n",
            "\n",
            "[time elapsed: 9m 8s  ;  iterations: 1500 (75.0%)  ;  loss: 1.642]\n",
            "What do the blood and.\n",
            "\n",
            "CAPEY:\n",
            "That that some a would,\n",
            "And Frie less a drate and thoud of What soll:\n",
            "The he with grow, are how brought it plack:\n",
            "What's that to to have plats, their a caum; and him shall \n",
            "\n",
            "[time elapsed: 9m 45s  ;  iterations: 1600 (80.0%)  ;  loss: 1.792]\n",
            "Wher to thou shall a mander disme\n",
            "And tedess onen mein you so beous;\n",
            "To have love of that my ford oldilt,\n",
            "I will to his faite all a dead-dound bet;\n",
            "Hath wasse of you now, as my lear.\n",
            "\n",
            "DORCS:\n",
            "I'll not yo \n",
            "\n",
            "[time elapsed: 10m 21s  ;  iterations: 1700 (85.0%)  ;  loss: 1.577]\n",
            "Where are shere deny!\n",
            "\n",
            "CLATHAUS:\n",
            "I have the deather! him him dindon.\n",
            "\n",
            "Sises.\n",
            "\n",
            "KING RICHARD III:\n",
            "I pronousa day of mine thmoscaous not\n",
            "Coosta upon thy are discorder befes:\n",
            "That must confelly the did sona \n",
            "\n",
            "[time elapsed: 10m 58s  ;  iterations: 1800 (90.0%)  ;  loss: 1.753]\n",
            "When citters: take prided:\n",
            "Could you might?\n",
            "\n",
            "MIRDA:\n",
            "Seep cather: death mind's prail's them man then:\n",
            "Now thought must it made here remious ert prise\n",
            "This it shame, this affool with the men,\n",
            "And crother  \n",
            "\n",
            "[time elapsed: 11m 34s  ;  iterations: 1900 (95.0%)  ;  loss: 1.411]\n",
            "Wher ween well!\n",
            "\n",
            "MENENIUS:\n",
            "I, breast that that my count that when still\n",
            "not the mane ongus, I tears were were and not.\n",
            "\n",
            "BUCKINGHAM:\n",
            "If me, and were and was have cen,\n",
            "And chantoneited of a shame the swal \n",
            "\n",
            "[time elapsed: 12m 10s  ;  iterations: 2000 (100.0%)  ;  loss: 1.757]\n",
            "Whold and the reing dined\n",
            "Our culd than this for they lits right delves.\n",
            "\n",
            "HENRY BOLINGBROKE:\n",
            "When, wed you is that is contery as grans;\n",
            "And comes it with is the not me but should is\n",
            "Offoit bo with seeme \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "8584d3be75d90a5197e7133411e0021d",
          "grade": false,
          "grade_id": "cell-ff9d72dafefa0a23",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "2J1BX7siyxKs",
        "colab_type": "text"
      },
      "source": [
        "### Training Loss\n",
        "\n",
        "Plotting the the losses that were computed during training can provide a further indication that the network was indeed learning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "77791204e14b67d3ad68d70695c479a6",
          "grade": false,
          "grade_id": "cell-f91bb597844b8f7d",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "is_executing": false
        },
        "id": "Dxnc6mA0yxKs",
        "colab_type": "code",
        "outputId": "bc098280-e81b-42d5-fcc4-37791fd98472",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.grid(True)\n",
        "plt.xlabel('# of iterations (divided by plot_every)')\n",
        "plt.ylabel('average loss')\n",
        "plt.plot(all_losses)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f0d0b5d6780>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEHCAYAAACjh0HiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "a376c5ed8b8f2dff9ea4731669bc8a49",
          "grade": false,
          "grade_id": "cell-dac1f386e2b526f5",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "8-3ypyPgyxKt",
        "colab_type": "text"
      },
      "source": [
        "### Evaluating at Different Temperatures\n",
        "Every time we use the `evaluate` function to generate the distribution of the next character, we don't just use softmax as usual, but we also divide by a `temperature`.  \n",
        "Let's examine the effect of changing the temperature when generating text using our trained model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbhhHx76yxKu",
        "colab_type": "code",
        "outputId": "9f885f17-855e-40e9-df69-44d483935bec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "print(evaluate('Th', 400, temperature=0.1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The prince the for the sent the well.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "What the prince the for the for the for the for the for the dear is the for the for the for the for the for the for the for the for the king and the for the for the for the for the dear the for the for the for the for the for the for the for the for the for the for the for the for the for the for the king.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "What with the propples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17YobD4IyxKv",
        "colab_type": "code",
        "outputId": "8072b14e-8903-4265-b4cd-529494f0d0ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "print(evaluate('Th', 400, temperature=0.5))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thard let tister a made here right my come,\n",
            "When you the depose be to fall the conter.\n",
            "\n",
            "KING RICHARD II:\n",
            "And death is strike the for me me he may not mard:\n",
            "For my chath with the report her her I suppire\n",
            "All then the right her put the hearts man.\n",
            "\n",
            "ESCALUS:\n",
            "Where do my the reselves is to deedion,\n",
            "What the king a warry have be his good grace.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "What is the with the stally be and his with\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7gAFnHayxKx",
        "colab_type": "code",
        "outputId": "66db3745-3dab-407f-9897-6ccf7c574cb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "print(evaluate('Th', 400, temperature=0.8))  # the default value"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The did arms:\n",
            "Is deast face there for Sit in: and is inthey\n",
            "Give not mistrest one prosster intrust must good.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Let the is insumped you as I shall is too:\n",
            "when you shall your despire well for a colds\n",
            "My Lord that be cant gog's but reasin.\n",
            "But in the other to kneage is Luncales, fient there deans,\n",
            "And not may me;\n",
            "Which the deeds to ectry, and a be of Sit,\n",
            "Bit a kitagrand, Jone he is th\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqlIT8k_yxK0",
        "colab_type": "code",
        "outputId": "bc66d017-d46a-4d6e-c140-3146c60ae761",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        }
      },
      "source": [
        "print(evaluate('Th', 400, temperature=1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The you sosting York,\n",
            "I wament to you toos well and seigha.\n",
            "\n",
            "BUCKINGHAM:\n",
            "Go, sworg up.\n",
            "\n",
            "LADY.\n",
            "\n",
            "HASTINGS:\n",
            "O you hustime, in he renchar?\n",
            "\n",
            "DIUS:\n",
            "What down tone a plashire, semvoy, mesting; thear?\n",
            "Ought's dructry bother you, fiars, figten--spoth night?\n",
            "\n",
            "CLARET:\n",
            "When me have knot I loves murver?\n",
            "\n",
            "SAPUTIO:\n",
            "Ghind an I dable and his grives is I\n",
            "siry! came he is't it than I this pruthine,\n",
            "Las.\n",
            "\n",
            "Liedow'd cons\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBq1oZ8AyxK2",
        "colab_type": "code",
        "outputId": "26d0667d-a1d6-47f0-d3d0-7bb9d1986cca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "print(evaluate('Th', 400, temperature=1.5))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Than too ooken.\n",
            "Butunel. In fent imendeop!\n",
            "!istor this meachipdings a quess,\n",
            "We chorses an eal I poie? wet yluw's preat,\n",
            "Toged!\n",
            "\n",
            "Dell:\n",
            "His Datact:\n",
            "Which-caman.\n",
            "But me himherk was!\n",
            "O somgy broidind, what: the mideb.,\n",
            "'hose twest fleg-Our noblve\n",
            "To the bllood migin broude-\n",
            "Ga6'od egs the know I nuttay kings?\n",
            "\n",
            "PLq2OSkURCASS:\n",
            "Lill; divip hicgarbhestas you lont, wood.\n",
            "\n",
            "RUCIO:\n",
            "Rumsms QuUkers.\n",
            "\n",
            "BESVOLOZEME\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "33ad994fe23b1e288fc8ef61422435cd",
          "grade": false,
          "grade_id": "cell-08d4f5f563b097a0",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "oVvrWHquyxK4",
        "colab_type": "text"
      },
      "source": [
        "### Question 3.c\n",
        "How does the value of `temperature` affect the properties of the generated text?\n",
        "Specifically address the process of sampling a character from the next character distribution, and the effect `temperature` has on it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "73f841dadc6afd8d63765a083c3f8914",
          "grade": true,
          "grade_id": "cell-bfdb7d9e747067db",
          "locked": false,
          "points": 6,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "XxblQzSryxK4",
        "colab_type": "text"
      },
      "source": [
        "As the temperature decrease, the generated text includes repeated words. For example, with  `temperature = 0.1` the words \"for\" and \"the\" appear many time in the generated text, which are very frequent words in the language.\n",
        "As the `temperature` increase, but below 1,  the generated text includes  exsiting words, but still without correct sentence structure that has meaningful. When the `temperature` is higher than 1, the generated text includes both non existing words in English and wrong sentence structure. For example, the word \"hicgarbhestas\" is totally Gibberish.  \n",
        "\n",
        "In conclusion, We notice that as the `temperature` decreases, the distribution becomes more peaky — probabilities that were larger become even larger, and probabilities that were smaller become even smaller. On the other hand, as you increase `temperature`, the distribution becomes flatter — probabilities that were larger become smaller, and probabilities that were smaller become larger.\n",
        "\n"
      ]
    }
  ]
}